---
title: "week7 gibbs"
author: "kwon"
date: "2018년 11월 15일"
output: html_document
---

# Gibbs
## model
$$ y_i | \mu, \sigma^2 \sim N(\mu, \sigma^2) $$
$$ \mu \sim N(\mu_0, \sigma_0^2) $$
$$ \sigma^2 \sim IG(\nu_0, \beta_0) $$


$$ N(\mu|\frac{n\bar y/\sigma^2 + \mu_0/\sigma_0^2}
{n/\sigma^2 + 1/\sigma_0^2}, 
\frac{1}{n/\sigma^2 + 1/\sigma_0^2}) $$

$$ IG(\sigma^2 | \nu_0 + n/2, 
\beta_0 + \frac{\sum_{i=1}^n(y_i - \mu)^2}{2})$$

## Update
```{r setup, include=FALSE}
update_mu = function(n, ybar, sig2, mu_0, sig2_0){
  sig2_1 = 1 / (n/sig2 + 1/sig2_0)
  mu_1 = sig2_1*(n*ybar/sig2+ mu_0/sig2_0)
  result = rnorm(n=1, mu_1, sqrt(sig2_1))
  return(result)
}

update_sig2 = function(n, y, mu, nu_0, beta_0){
  nu_1 = nu_0 +n/2
  sumsq = sum((y-mu)^2)
  beta_1 = beta_0 + sumsq/2
  out_gamma = rgamma(1, nu_1, beta_1)
  return(1/out_gamma)
}
```

## Sampling
```{r}
gibbs = function(y, n_iter, init, prior){
  ybar =mean(y)
  n = length(y)
  
  mu_out = numeric(n_iter)
  sig2_out = numeric(n_iter)
  
  mu_now = init$mu
  
  ## Gibbs sampler
  for( i in 1:n_iter){
    sig2_now = update_sig2(n, y, mu_now, nu_0 = prior$nu_0, beta_0=prior$beta_0)
    mu_now = update_mu(n, ybar, sig2_now, mu_0 = prior$mu_0, sig2_0 = prior$sig2_0)
    
    sig2_out[i] = sig2_now
    mu_out[i] = mu_now
  }
  return (cbind(mu=mu_out, sig2=sig2_out))
}
```

## data and prior
```{r}
# data
y = c(1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)
ybar = mean(y)
n= length(y)

# prior
prior = list()
prior$mu_0 = 0
prior$sig2_0 = 1
prior$n_0 = 2
prior$s2_0 = 1
prior$nu_0 = prior$n_0 /2
prior$beta_0 = prior$n_0 * prior$s2_0 / 2 

```

## Run gibbs
```{r}
set.seed(1)
init = list()
init$mu = 0

post = gibbs(y, n_iter = 1e3, init=init, prior=prior)
```

```{r}
require("coda")
plot(as.mcmc(post))
summary(as.mcmc(post))
```

## Assessing Convergence
```{r}
plot(as.mcmc(post)[,1])
```
For trace, there should not be a trend. It should be staionary across iterations.

```{r}
# auto correlation
autocorr.plot(as.mcmc(post))
autocorr.diag(as.mcmc(post))

# effective sample size
effectiveSize(as.mcmc(post))
```

Auto correlated samples are less informative than independent samples. Lets suppose you are to find the best movie by asking to people. Randomly sampled 20 people would give more information than your 20 friends' movie preferences, because they are more likely to have similar interests.



