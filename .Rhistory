# evaluating ratio funciton
ratio = function(mu.prop, sigma.2.prop, mu.old, sigma.2.old){
dnorm(mu.prop, mu0, sqrt(tau.2.0)) *dinvchisq(sigma.2.prop, nu0, sigma.2.0) * likelihood(mu.prop, sigma.2.prop) /
(dnorm(mu.old, mu0, sqrt(tau.2.0)) * dinvchisq(sigma.2.old, nu0, sigma.2.0) * likelihood(mu.old, sigma.2.old))
}
# run gibbs sampler:
n.sim = 1000
mu.sim = numeric(n.sim)
sigma.2.sim = numeric(n.sim)
accept.prob = numeric(n.sim-1) # no need for final draw
# arbitrary chosen proposal
rho = 0.01
# starting values
mu.sim[1]=2
sigma.2.sim[1] = 2.5
for(t in 2:n.sim){
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] =
min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
if(runif(1) < accept.prob[t-1])
{
mu.sim[t] = mu.prop
sigma.2.sim[t] = sigma.2.prop
} else
{
mu.sim[t] = mu.sim[t-1]
sigma.2.sim[t] =sigma.2.sim[t-1]
}
}
runif(1)
accept.prob[1]
# run gibbs sampler:
n.sim = 1000
mu.sim = numeric(n.sim)
sigma.2.sim = numeric(n.sim)
accept.prob = numeric(n.sim-1) # no need for final draw
# arbitrary chosen proposal
rho = 0.01
# starting values
mu.sim[1]=2
sigma.2.sim[1] = 2.5
for(t in 2:n.sim){
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] = min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
if(runif(1) < accept.prob[t-1])
{
mu.sim[t] = mu.prop
sigma.2.sim[t] = sigma.2.prop
} else
{
mu.sim[t] = mu.sim[t-1]
sigma.2.sim[t] =sigma.2.sim[t-1]
}
}
if(1>2)
{}
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] = min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
t=1
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] = min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
t=2
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] = min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
mu.sim[2]
mu.sim[3]
sqrt(rho)
mu.prop
sigma.2.prop
ratio(mu.prop, sigma.2.prop, mu.sim[2], sigma.2.sim[2])
dnorm(mu.prop, mu0, sqrt(tau.2.0))
dinvchisq(sigma.2.sim.prop, nu0, sigma.2.0)
dinvchisq(sigma.2.prop, nu0, sigma.2.0)
sigma.2.prop
nu0
sigma.2.0
dinvchisq(2.5, 0, 1.17)
df/2
0/2
df=0
0/2
df/2
df/2^(df/2)
(df/2)^(df/2)
gamma(df/2)
gamma(0)
gamma(1)
# setting
n = 271
ybar = 1.4
s.2 = 1.684
mu0 = 1.10
tau.2.0 = sigma.2.0 = 1.17
nu0 = 1
# convenience functions
# inverse chi-square density
dinvchisq = function(x, df, scale){
if(x>0)
((df/2)^(df/2) / gamma(df/2)) * scale^df *x^(-(df/2+1))*exp(-df*scale/(2*x))
else 0
}
likelihood = function(mu, sigma.2){
sigma.2^(-n/2)*exp(-(n-1)*s.2/(2*sigma.2))*exp(-n*(mu-ybar)^2/(2*sigma.2))
}
# evaluating ratio funciton
ratio = function(mu.prop, sigma.2.prop, mu.old, sigma.2.old){
dnorm(mu.prop, mu0, sqrt(tau.2.0)) *dinvchisq(sigma.2.prop, nu0, sigma.2.0) * likelihood(mu.prop, sigma.2.prop) /
(dnorm(mu.old, mu0, sqrt(tau.2.0)) * dinvchisq(sigma.2.old, nu0, sigma.2.0) * likelihood(mu.old, sigma.2.old))
}
# run gibbs sampler:
n.sim = 1000
mu.sim = numeric(n.sim)
sigma.2.sim = numeric(n.sim)
accept.prob = numeric(n.sim-1) # no need for final draw
# arbitrary chosen proposal
rho = 0.01
# starting values
mu.sim[1]=2
sigma.2.sim[1] = 2.5
for(t in 2:n.sim){
mu.prop = rnorm(1, mu.sim[t-1], sqrt(rho))
sigma.2.prop = rnorm(1, sigma.2.sim[t-1], sqrt(rho))
accept.prob[t-1] = min(ratio(mu.prop, sigma.2.prop, mu.sim[t-1], sigma.2.sim[t-1]), 1)
if(runif(1) < accept.prob[t-1])
{
mu.sim[t] = mu.prop
sigma.2.sim[t] = sigma.2.prop
} else
{
mu.sim[t] = mu.sim[t-1]
sigma.2.sim[t] =sigma.2.sim[t-1]
}
}
sigma.2.sim
mean(accpet.prob)
accept.prob
mean(accept.prob)
plot(mu.sim)
plot(mu.sim, sigma.2.sim)
plot(mu.sim, sigma.2.sim, type="l")
require(rjags)
d = read.table("rattumor.txt", header=T)
thetahat = d$y/d$N
Etheta = mean(thetahat)
Vtheta = var(thetahat)
(alphahat = Etheta*(Etheta*(1-Etheta)/Vtheta-1))
(betahat = alphahat*(1/Etheta-1))
initial.vals = list(list(alpha=0.01, beta=0.1),
list(alpha=100, beta=0.1),
list(alpha=0.01, beta=1000),
list(alpha=100, beta=1000))
m1 = jags.model("rattumor1.bug", d, inits = initial.vals, n.chains= 4, n.adapt = 1000)
plot(x1, smooth=FALSE)
# burn-in
update(m1, 1000)
x1 = coda.samples(m1, c("alpha", "beta"), n.iter=2000)
plot(x1, smooth=FALSE)
plot(as.matrix(x1)[,c('alpha', 'beta')], pch=".", cex=2)
data = read.table("pollsdata.txt")
data = read.table("polls2016.txt", header=T)
data = read.table("polls20161.txt", header=T)
data = read.table("polls2016.txt", header=T)
getwd
getwd()
data = read.table("polls2016.txt", header=T)
data
setwd("C:/Users/tony/Documents/MCS/STAT 578 Advanced Bayesian Modeling/code files")
Flintdata = read.table("flint-data-simple.csv", header=T, sep="\t")
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
s.2 = var(log(Flintdata))
post.sigma.2.sim = (n-1)*s.2/rchisq(1000, n-1)
rchisq(1000, n-1)
s.2
str(s.2)
s.2*2
Flintdata = read.table("flint-data-simple.csv", header=T)
Flintdata = read.csv("flint-data-simple.csv", header=T)
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
Flintdata
Flintdata = read.csv("flint-data-simple.txt", header=T)
Flintdata = read.txt("flint-data-simple.txt", header=T)
Flintdata = read.table("flint-data-simple.txt", header=T)
getwd()
dir()
dir()
Flintdata = read.table("flint-data-simple.txt", header=T)
Flintdata = read.table("flint-data-simple.txt", header=T, sep="\t")
Flintdata
Flintdata = read.table("flint-data-simple.txt", header=T, sep="\t")
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
s.2 = var(log(Flintdata))
dir()
post.sigma.2.sim = (n-1)*s.2/rchisq(1000, n-1)
s.2
str(s.2)
s.2[1]
n
ybar
Flintdata = read.table("flint-data-simple.txt", header=T, sep="\t")
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
Flintdata
Flintdata = read.table("flint-data-simple.txt", header=T)
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
Flintdata
str(Flintdata)
Flintdata = read.table("flint-data-simple.txt", header=T, sep="\t")
Flintdata = read.table("flint-data-simple.txt", header=T, sep="\t")
n = nrow(Flintdata)
ybar = mean(log(Flintdata))
Flintdata = read.table("flint-data-simple.csv", header=T)
# data
y= c(1.2,1.4, -0.5, 0.3, 0.9,2.3,1.0,0.1,1.3,1.9)
# g function
lg = function(mu, n, ybar){
mu2 = n(ybar*mu - mu^2/2)-log(1+mu^2)
return(mu2)
}
# data
y= c(1.2,1.4, -0.5, 0.3, 0.9,2.3,1.0,0.1,1.3,1.9)
# g function
lg = function(mu, n, ybar){
mu2 = n(ybar*mu - mu^2/2)-log(1+mu^2)
return(mu2)
}
# random walk metroplis hastings sampler
mh = function(n, ybar, n_iter, mu_init, cand_sd){
# step 1: initailize
mu_out = numeric(n_iter)
accpt = 0
mu_now = mu_init
lg_now = lg(mu_now, n, ybar)
# step 2: iterate
for(i in 1:n_iter){
# 2a
mu_cand = rnorm(n=1, mu_now, cand_sd) # draw a candidate
# 2b
lg_cand = lg(mu_cand, n, ybar) # evaluate log of g with the candidate
lalpha = lg_cand -lg_now # log of acceptance ratio
alpha = exp(lalpha)
# 2c
u= runif(1)
if(u < alpha){
mu_now = mu_cand
accpt = accpt+1
lg_now = lg_cand
}
# collect results
mu_out[i] = mu_now # save iterations' value of mu
}
return( list(mu_out, accpt/n_iter))
}
ybar = mean(y)
n = length(y)
hist(y, freq=FALSE, xlim=c(-1,3.0)) # hist of data
curve(dt(x=x, df=1), lty=2, add=TRUE) # prior
points(y, rep(0,n), pch=1) # individual data points
points(ybar, 0, pch=19)
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
# data
y= c(1.2,1.4, -0.5, 0.3, 0.9,2.3,1.0,0.1,1.3,1.9)
# g function
lg = function(mu, n, ybar){
mu2 = n*(ybar*mu - mu^2/2)-log(1+mu^2)
return(mu2)
}
# random walk metroplis hastings sampler
mh = function(n, ybar, n_iter, mu_init, cand_sd){
# step 1: initailize
mu_out = numeric(n_iter)
accpt = 0
mu_now = mu_init
lg_now = lg(mu_now, n, ybar)
# step 2: iterate
for(i in 1:n_iter){
# 2a
mu_cand = rnorm(n=1, mu_now, cand_sd) # draw a candidate
# 2b
lg_cand = lg(mu_cand, n, ybar) # evaluate log of g with the candidate
lalpha = lg_cand -lg_now # log of acceptance ratio
alpha = exp(lalpha)
# 2c
u= runif(1)
if(u < alpha){
mu_now = mu_cand
accpt = accpt+1
lg_now = lg_cand
}
# collect results
mu_out[i] = mu_now # save iterations' value of mu
}
return( list(mu_out, accpt/n_iter))
}
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
traceplot(as.mcmc(post$mu))
require("coda")
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
traceplot(as.mcmc(post$mu))
post$mu
str(post)
# data
y= c(1.2,1.4, -0.5, 0.3, 0.9,2.3,1.0,0.1,1.3,1.9)
# g function
lg = function(mu, n, ybar){
mu2 = n*(ybar*mu - mu^2/2)-log(1+mu^2)
return(mu2)
}
# random walk metroplis hastings sampler
mh = function(n, ybar, n_iter, mu_init, cand_sd){
# step 1: initailize
mu_out = numeric(n_iter)
accpt = 0
mu_now = mu_init
lg_now = lg(mu_now, n, ybar)
# step 2: iterate
for(i in 1:n_iter){
# 2a
mu_cand = rnorm(n=1, mu_now, cand_sd) # draw a candidate
# 2b
lg_cand = lg(mu_cand, n, ybar) # evaluate log of g with the candidate
lalpha = lg_cand -lg_now # log of acceptance ratio
alpha = exp(lalpha)
# 2c
u= runif(1)
if(u < alpha){
mu_now = mu_cand
accpt = accpt+1
lg_now = lg_cand
}
# collect results
mu_out[i] = mu_now # save iterations' value of mu
}
return( list(mu = mu_out, accpt=accpt/n_iter))
}
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
traceplot(as.mcmc(post$mu))
post$mu
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
traceplot(as.mcmc(post$mu))
set.seed(5)
post = mh(n, ybar, n_iter=1e3, mu_init=0, cand_sd =3.0)
str(post)
traceplot(as.mcmc(post$mu))
mean(post$accpt)
post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.05)
post$accpt
post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.1)
post$accpt
post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.9)
post$accpt
post = mh(n=n, ybar=ybar, n_iter=1e3, mu_init=0.0, cand_sd=0.9)
post$accpt
traceplot(as.mcmc(post$mu))
Election = seq(1952, 2004, 4)
IncumbentPct = c(44.6, 57.8, 49.9, 61.3, 49.6, 61.8, 49.0, 44.7, 59.2, 53.9, 46.5, 54.7, 50.3, 51.2)
IncomeGrowth = c(2.4, 2.9, 0.8, 4.2, 3.0, 3.6, 1.1, -0.4, 3.9, 2.3, 0.4, 1.0, 2.4, 1.9)
bp = data.frame(Election, IncumbentPct, IncomeGrowth)
Election = seq(1952, 2004, 4)
IncumbentPct = c(44.6, 57.8, 49.9, 61.3, 49.6, 61.8, 49.0, 44.7, 59.2, 53.9, 46.5, 54.7, 50.3, 51.2)
IncomeGrowth = c(2.4, 2.9, 0.8, 4.2, 3.0, 3.6, 1.1, -0.4, 3.9, 2.3, 0.4, 1.0, 2.4, 1.9)
bp = data.frame(Election, IncumbentPct, IncomeGrowth)
plot(bp$IncumbentPct, bp$IncomeGrowth)
plot(bp$IncumbentPct, bp$IncomeGrowth, ann = bp$Election)
mod = lm(IncumbentPct~IncomeGrowth, data=bp)
(X = model.matrix(mod))
betahat = coef(mod)
smod=summary(mod)
s.2 = smod$sigma^2
Vbeta = smod$cov.unscaled
n.minus.k = df.residual(mod)
library(MASS) # provides mvrnorm, multivariate normal
Nsim = 1000
# inverse cai square(n-k degree of freedom)
post.sigma.2.sim = n.minus.k*s.2/rchisq(Nsim, n.minus.k)
post.beta.sim = matrix(NA, Nsim, length(betahat))
# simulate beta
for(s in 1:Nsim)
post.beta.sim[s,] = mvrnorm(1, betahat, post.sigma.2.sim[s]*Vbeta)
str(post.beta.sim)
mean(post.beta.sim)
# posterior interval
quantile(post.sigma.2.sim, c(0.025, 0.975))
apply(post.beta.sim, 2, quantile, c(0.025, 0.975))
confint(mod)
mean(post.beta.sim[,2] > 0)
# incomeGrowth on 2008 was 0.75
# simulate from posterior predictive distribution
post.pred.y.sim = rnorm(Nsim, post.beta.sim[,1]+post.beta.sim[,2]*0.75,sqrt(post.sigma.2.sim))
quantile(post.pred.y.sim, c(0.025, 0.975))
# classical prediction
predict(mod, data.frame(IncomeGrowth=0.75), interval="prediction")
# posterior predictive probability of 2008 incumbent victory
mean(post.pred.y.sim > 50)
mod$fitted.values
mean(mod$fitted.values>50)
par(mfrow=c(2,2))
plot(mod)
error.std.sim = matrix(NA, Nsim, nrow(bp))
for(s in 1:Nsim)
error.std.sim[s,] = (bp$IncumbentPct - X %*% cbind(post.beta.sim[s,])) / sqrt(post.sigma.2.sim[s])
# rnorm can be used as it is standardized and independent
ref.std.normal = matrix(rnorm(Nsim*nrow(bp)), Nsim, nrow(bp))
max.t.rep = apply(abs(ref.std.normal),1, max)
max.t.sim = apply(abs(error.std.sim), 1, max)
mean(max.t.rep >= max.t.sim)
max.t.rep = apply(abs(ref.std.normal),1, max)
max.t.sim = apply(abs(error.std.sim), 1, max)
mean(max.t.rep >= max.t.sim)
median.t.rep = apply(abs(ref.std.normal), 1, max)/ apply(abs(ref.std.normal), 1, median)
median.t.sim = apply(abs(error.std.sim), 1, max)/ apply(abs(error.std.sim), 1, median)
mean(median.t.rep >= median.t.sim)
mean(abs(cor(t(ref.std.normal), bp$Election)) >= abs(cor(t(error.std.sim), bp$Election)))
library("tm")
abs = c("line chart", "this chart", "a chart")
tm_map(abs)
tm_map(abs, stopwords("a"))
text = c("line chart", "this chart", "a chart")
tm_map(text, abs, stopwords("a"))
tm_map(text, stopwords("a"))
tm_map(text, c(stopwords("english"),"this","a"))
text
tm_map(text, removeWords, c(stopwords("english"),"this","a"))
class(text)
gsub(text, "a")
text
gsub("a",text)
gsub(pattern = "a", x=text)
gsub(pattern = "a", x=text, replacement = "")
gsub(pattern = c("a ","this "), x=text, replacement = "")
pzw = (0.5*pd)/(0.5*pd+0.5*pb)
source('~/.active-rstudio-document', echo=TRUE)
pzw
wc*pzw/(sum(wc*pzw))
pzw
pd2= wc*pzw/(sum(wc*pzw))
wc*pd
wc*pd/sum(wc*pd)
pzw
pzw^(wc)
prod(pzw^(wc))
log(prod(pzw^(wc)))
log(prod(pd^(wc)))
data= read.csv("flintdata.csv")
ls
ls()
dir()
getwd()
setwd("C:/Users/tony/Documents/MCS/STAT 578 Advanced Bayesian Modeling/code files/")
dir()
data= read.csv("flint-data-simple.txt", header=T)
data
data= read.table("flint-data-simple.txt", header=T)
data
data= read.table("flint-data-simple.txt", header=T, sep="\t")
data
data= read.table("flint-data-simple.txt", header=T, sep="\t")
data
plot(data)
plot(data$Pb.Bottle.1..ppb....First.Draw)
plot(data$Pb.Bottle.1..ppb....First.Draw, type="l")
plot(data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing, type="l")
idx = nrow(data)
plot(idx, data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing, type="l")
plot(idx, c(data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing), type="l")
plot(idx, cbind(data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing), type="l")
plot(1:idx, cbind(data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing), type="l")
1:idx
idx = numeric(nrow(data))
dix
idx
idx = nrow(data)
dim(cbind(data$Pb.Bottle.1..ppb....First.Draw, data$Pb.Bottle.2..ppb....45.secs.flushing))
idx
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
head(flint)
head(flint)
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
head(flint)
head(flint)
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
(flint)
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
(flint)
flint= read.table("flint-data-simple.txt", header=T, sep="\t")
head(flint)
d1 = list(loglead = log(flint[,c("FirstDraw", "After45Sec", "After2Min")]),
betadraw0 = c(0,0,0),
Sigmabetadrawinv = rbind(c(0.0001, 0, 0),
c(0, 0.0001, 0),
c(0, 0, 0.0001)))
